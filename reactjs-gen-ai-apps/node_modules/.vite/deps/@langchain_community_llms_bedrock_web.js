import {
  LLM
} from "./chunk-P3OKYPYX.js";
import {
  GenerationChunk
} from "./chunk-QVZUGSRS.js";
import "./chunk-52BLXYPB.js";
import {
  getEnvironmentVariable
} from "./chunk-Y4Y4AWYL.js";
import {
  EventStreamCodec,
  HttpRequest,
  SignatureV4
} from "./chunk-MSF4XV6C.js";
import {
  Sha256
} from "./chunk-SKQVTHOL.js";
import "./chunk-KD35WQG2.js";
import {
  fromUtf8,
  toUtf8
} from "./chunk-HSLQ6YIW.js";
import "./chunk-OH5TXUMX.js";
import "./chunk-WXXH56N5.js";

// node_modules/@langchain/community/dist/utils/bedrock.js
var BedrockLLMInputOutputAdapter = class {
  /** Adapter class to prepare the inputs from Langchain to a format
  that LLM model expects. Also, provides a helper function to extract
  the generated text from the model response. */
  static prepareInput(provider, prompt, maxTokens = 50, temperature = 0, stopSequences = void 0, modelKwargs = {}, bedrockMethod = "invoke") {
    const inputBody = {};
    if (provider === "anthropic") {
      inputBody.prompt = prompt;
      inputBody.max_tokens_to_sample = maxTokens;
      inputBody.temperature = temperature;
      inputBody.stop_sequences = stopSequences;
    } else if (provider === "ai21") {
      inputBody.prompt = prompt;
      inputBody.maxTokens = maxTokens;
      inputBody.temperature = temperature;
      inputBody.stopSequences = stopSequences;
    } else if (provider === "meta") {
      inputBody.prompt = prompt;
      inputBody.max_gen_len = maxTokens;
      inputBody.temperature = temperature;
    } else if (provider === "amazon") {
      inputBody.inputText = prompt;
      inputBody.textGenerationConfig = {
        maxTokenCount: maxTokens,
        temperature
      };
    } else if (provider === "cohere") {
      inputBody.prompt = prompt;
      inputBody.max_tokens = maxTokens;
      inputBody.temperature = temperature;
      inputBody.stop_sequences = stopSequences;
      if (bedrockMethod === "invoke-with-response-stream") {
        inputBody.stream = true;
      }
    }
    return { ...inputBody, ...modelKwargs };
  }
  /**
   * Extracts the generated text from the service response.
   * @param provider The provider name.
   * @param responseBody The response body from the service.
   * @returns The generated text.
   */
  // eslint-disable-next-line @typescript-eslint/no-explicit-any
  static prepareOutput(provider, responseBody) {
    var _a, _b, _c, _d, _e, _f, _g;
    if (provider === "anthropic") {
      return responseBody.completion;
    } else if (provider === "ai21") {
      return ((_c = (_b = (_a = responseBody == null ? void 0 : responseBody.completions) == null ? void 0 : _a[0]) == null ? void 0 : _b.data) == null ? void 0 : _c.text) ?? "";
    } else if (provider === "cohere") {
      return ((_e = (_d = responseBody == null ? void 0 : responseBody.generations) == null ? void 0 : _d[0]) == null ? void 0 : _e.text) ?? (responseBody == null ? void 0 : responseBody.text) ?? "";
    } else if (provider === "meta") {
      return responseBody.generation;
    }
    return (_g = (_f = responseBody.results) == null ? void 0 : _f[0]) == null ? void 0 : _g.outputText;
  }
};

// node_modules/@langchain/community/dist/llms/bedrock/web.js
var PRELUDE_TOTAL_LENGTH_BYTES = 4;
var Bedrock = class extends LLM {
  get lc_aliases() {
    return {
      model: "model_id",
      region: "region_name"
    };
  }
  get lc_secrets() {
    return {
      "credentials.accessKeyId": "BEDROCK_AWS_ACCESS_KEY_ID",
      "credentials.secretAccessKey": "BEDROCK_AWS_SECRET_ACCESS_KEY"
    };
  }
  get lc_attributes() {
    return { region: this.region };
  }
  _llmType() {
    return "bedrock";
  }
  static lc_name() {
    return "Bedrock";
  }
  constructor(fields) {
    super(fields ?? {});
    Object.defineProperty(this, "model", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: "amazon.titan-tg1-large"
    });
    Object.defineProperty(this, "region", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "credentials", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "temperature", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "maxTokens", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "fetchFn", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "endpointHost", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "stopSequences", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "modelKwargs", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: void 0
    });
    Object.defineProperty(this, "codec", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: new EventStreamCodec(toUtf8, fromUtf8)
    });
    Object.defineProperty(this, "streaming", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: false
    });
    Object.defineProperty(this, "lc_serializable", {
      enumerable: true,
      configurable: true,
      writable: true,
      value: true
    });
    this.model = (fields == null ? void 0 : fields.model) ?? this.model;
    const allowedModels = ["ai21", "anthropic", "amazon", "cohere", "meta"];
    if (!allowedModels.includes(this.model.split(".")[0])) {
      throw new Error(`Unknown model: '${this.model}', only these are supported: ${allowedModels}`);
    }
    const region = (fields == null ? void 0 : fields.region) ?? getEnvironmentVariable("AWS_DEFAULT_REGION");
    if (!region) {
      throw new Error("Please set the AWS_DEFAULT_REGION environment variable or pass it to the constructor as the region field.");
    }
    this.region = region;
    const credentials = fields == null ? void 0 : fields.credentials;
    if (!credentials) {
      throw new Error("Please set the AWS credentials in the 'credentials' field.");
    }
    this.credentials = credentials;
    this.temperature = (fields == null ? void 0 : fields.temperature) ?? this.temperature;
    this.maxTokens = (fields == null ? void 0 : fields.maxTokens) ?? this.maxTokens;
    this.fetchFn = (fields == null ? void 0 : fields.fetchFn) ?? fetch.bind(globalThis);
    this.endpointHost = (fields == null ? void 0 : fields.endpointHost) ?? (fields == null ? void 0 : fields.endpointUrl);
    this.stopSequences = fields == null ? void 0 : fields.stopSequences;
    this.modelKwargs = fields == null ? void 0 : fields.modelKwargs;
    this.streaming = (fields == null ? void 0 : fields.streaming) ?? this.streaming;
  }
  /** Call out to Bedrock service model.
      Arguments:
        prompt: The prompt to pass into the model.
  
      Returns:
        The string generated by the model.
  
      Example:
        response = model.call("Tell me a joke.")
    */
  async _call(prompt, options, runManager) {
    const service = "bedrock-runtime";
    const endpointHost = this.endpointHost ?? `${service}.${this.region}.amazonaws.com`;
    const provider = this.model.split(".")[0];
    if (this.streaming) {
      const stream = this._streamResponseChunks(prompt, options, runManager);
      let finalResult;
      for await (const chunk of stream) {
        if (finalResult === void 0) {
          finalResult = chunk;
        } else {
          finalResult = finalResult.concat(chunk);
        }
      }
      return (finalResult == null ? void 0 : finalResult.text) ?? "";
    }
    const response = await this._signedFetch(prompt, options, {
      bedrockMethod: "invoke",
      endpointHost,
      provider
    });
    const json = await response.json();
    if (!response.ok) {
      throw new Error(`Error ${response.status}: ${json.message ?? JSON.stringify(json)}`);
    }
    const text = BedrockLLMInputOutputAdapter.prepareOutput(provider, json);
    return text;
  }
  async _signedFetch(prompt, options, fields) {
    const { bedrockMethod, endpointHost, provider } = fields;
    const inputBody = BedrockLLMInputOutputAdapter.prepareInput(provider, prompt, this.maxTokens, this.temperature, options.stop ?? this.stopSequences, this.modelKwargs, fields.bedrockMethod);
    const url = new URL(`https://${endpointHost}/model/${this.model}/${bedrockMethod}`);
    const request = new HttpRequest({
      hostname: url.hostname,
      path: url.pathname,
      protocol: url.protocol,
      method: "POST",
      body: JSON.stringify(inputBody),
      query: Object.fromEntries(url.searchParams.entries()),
      headers: {
        // host is required by AWS Signature V4: https://docs.aws.amazon.com/general/latest/gr/sigv4-create-canonical-request.html
        host: url.host,
        accept: "application/json",
        "content-type": "application/json"
      }
    });
    const signer = new SignatureV4({
      credentials: this.credentials,
      service: "bedrock",
      region: this.region,
      sha256: Sha256
    });
    const signedRequest = await signer.sign(request);
    const response = await this.caller.callWithOptions({ signal: options.signal }, async () => this.fetchFn(url, {
      headers: signedRequest.headers,
      body: signedRequest.body,
      method: signedRequest.method
    }));
    return response;
  }
  invocationParams(options) {
    return {
      model: this.model,
      region: this.region,
      temperature: this.temperature,
      maxTokens: this.maxTokens,
      stop: (options == null ? void 0 : options.stop) ?? this.stopSequences,
      modelKwargs: this.modelKwargs
    };
  }
  async *_streamResponseChunks(prompt, options, runManager) {
    var _a;
    const provider = this.model.split(".")[0];
    const bedrockMethod = provider === "anthropic" || provider === "cohere" || provider === "meta" ? "invoke-with-response-stream" : "invoke";
    const service = "bedrock-runtime";
    const endpointHost = this.endpointHost ?? `${service}.${this.region}.amazonaws.com`;
    const response = await this._signedFetch(prompt, options, {
      bedrockMethod,
      endpointHost,
      provider
    });
    if (response.status < 200 || response.status >= 300) {
      throw Error(`Failed to access underlying url '${endpointHost}': got ${response.status} ${response.statusText}: ${await response.text()}`);
    }
    if (provider === "anthropic" || provider === "cohere" || provider === "meta") {
      const reader = (_a = response.body) == null ? void 0 : _a.getReader();
      const decoder = new TextDecoder();
      for await (const chunk of this._readChunks(reader)) {
        const event = this.codec.decode(chunk);
        if (event.headers[":event-type"] !== void 0 && event.headers[":event-type"].value !== "chunk" || event.headers[":content-type"].value !== "application/json") {
          throw Error(`Failed to get event chunk: got ${chunk}`);
        }
        const body = JSON.parse(decoder.decode(event.body));
        if (body.message) {
          throw new Error(body.message);
        }
        if (body.bytes !== void 0) {
          const chunkResult = JSON.parse(decoder.decode(Uint8Array.from(atob(body.bytes), (m) => m.codePointAt(0) ?? 0)));
          const text = BedrockLLMInputOutputAdapter.prepareOutput(provider, chunkResult);
          yield new GenerationChunk({
            text,
            generationInfo: {}
          });
          void (runManager == null ? void 0 : runManager.handleLLMNewToken(text));
        }
      }
    } else {
      const json = await response.json();
      const text = BedrockLLMInputOutputAdapter.prepareOutput(provider, json);
      yield new GenerationChunk({
        text,
        generationInfo: {}
      });
      void (runManager == null ? void 0 : runManager.handleLLMNewToken(text));
    }
  }
  // eslint-disable-next-line @typescript-eslint/no-explicit-any
  _readChunks(reader) {
    function _concatChunks(a, b) {
      const newBuffer = new Uint8Array(a.length + b.length);
      newBuffer.set(a);
      newBuffer.set(b, a.length);
      return newBuffer;
    }
    function getMessageLength(buffer) {
      if (buffer.byteLength < PRELUDE_TOTAL_LENGTH_BYTES)
        return 0;
      const view = new DataView(buffer.buffer, buffer.byteOffset, buffer.byteLength);
      return view.getUint32(0, false);
    }
    return {
      async *[Symbol.asyncIterator]() {
        let readResult = await reader.read();
        let buffer = new Uint8Array(0);
        while (!readResult.done) {
          const chunk = readResult.value;
          buffer = _concatChunks(buffer, chunk);
          let messageLength = getMessageLength(buffer);
          while (buffer.byteLength >= PRELUDE_TOTAL_LENGTH_BYTES && buffer.byteLength >= messageLength) {
            yield buffer.slice(0, messageLength);
            buffer = buffer.slice(messageLength);
            messageLength = getMessageLength(buffer);
          }
          readResult = await reader.read();
        }
      }
    };
  }
};
export {
  Bedrock
};
//# sourceMappingURL=@langchain_community_llms_bedrock_web.js.map
